{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tracemalloc\n",
    "import random\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score , recall_score\n",
    "\n",
    "# Path to the dataset\n",
    "train_path = './assets/train/'\n",
    "test_path = './assets/test/'\n",
    "\n",
    "# Feature extractor (SIFT)\n",
    "sift = cv2.SIFT_create(contrastThreshold=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_descriptors_from_image(image_path):\n",
    "    \"\"\"\n",
    "    Extract exactly a specified number of descriptors from an image using SIFT.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image not found or invalid: {image_path}\")\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    \n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        raise ValueError(f\"No descriptors found in image: {image_path}\")\n",
    "\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_descriptors_all(data_path):\n",
    "    \"\"\"\n",
    "    Collect descriptors and their corresponding labels.\n",
    "    \"\"\"\n",
    "    all_descriptors = []\n",
    "    all_labels = []\n",
    "    \n",
    "    classes = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n",
    "    \n",
    "    num_des_tot = 0\n",
    "    num_des_class_dist = []\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_folder = os.path.join(data_path, class_name)\n",
    "        # print(f\"Processing class: {class_name}\")\n",
    "        \n",
    "        num_des_class = 0\n",
    "        for image_name in os.listdir(class_folder):\n",
    "            if image_name.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                image_path = os.path.join(class_folder, image_name)\n",
    "                try:\n",
    "                    # Extract descriptors for this image\n",
    "                    descriptors = extract_descriptors_from_image(image_path)\n",
    "                    \n",
    "                    # Append descriptors and corresponding labels\n",
    "                    all_descriptors += descriptors.tolist()\n",
    "                    all_labels += [i]*len(descriptors)\n",
    "                    num_des_class += len(descriptors)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error processing {image_name}: {e}\")\n",
    "        num_des_tot += num_des_class\n",
    "        num_des_class_dist.append(num_des_class)\n",
    "    print(f'total number of descriptors: {num_des_tot}')\n",
    "    print(f'number of descriptors per class: {num_des_class_dist}')\n",
    "    \n",
    "    # Convert to NumPy arrays\n",
    "    all_descriptors = np.array(all_descriptors)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    return all_descriptors, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_descriptors_with_labels(data_path):\n",
    "    \"\"\"\n",
    "    Collect descriptors and their corresponding labels.\n",
    "    \"\"\"\n",
    "    all_descriptors = []\n",
    "    all_labels = []\n",
    "    \n",
    "    classes = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n",
    "\n",
    "    num_des_tot = 0\n",
    "    num_des_class_dist = []\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_folder = os.path.join(data_path, class_name)\n",
    "        # print(f\"Processing class: {class_name}\")\n",
    "        \n",
    "        for image_name in os.listdir(class_folder):\n",
    "            if image_name.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                image_path = os.path.join(class_folder, image_name)\n",
    "                try:\n",
    "                    # Extract descriptors for this image\n",
    "                    descriptors = extract_descriptors_from_image(image_path)\n",
    "                    all_descriptors.append(descriptors.tolist())\n",
    "                    all_labels.append(i)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error processing {image_name}: {e}\")\n",
    "    \n",
    "    # Convert to NumPy arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    return all_descriptors, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of descriptors: 104008\n",
      "number of descriptors per class: [13465, 15119, 5421, 8680, 10758, 14686, 18524, 8025, 2550, 6780]\n",
      "Descriptor extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Extract descriptors and labels\n",
    "descriptors_pool, labels_pool = collect_descriptors_all(train_path)\n",
    "print(\"Descriptor extraction completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. RF codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct RF codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 5\n",
    "max_depth = 4\n",
    "\n",
    "max_leaf_nodes = np.pow(2, max_depth)\n",
    "codebook_size = np.pow(2, max_depth) * n_estimators\n",
    "\n",
    "rf_code = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, bootstrap=True, random_state=None, max_samples=0.9, max_features=\"sqrt\", criterion='entropy')\n",
    "rf_code.fit(descriptors_pool, labels_pool.ravel())\n",
    "\n",
    "leaf_indices = []\n",
    "for tree in rf_code.estimators_:\n",
    "    # Mask for leaf nodes\n",
    "    is_leaf = tree.tree_.children_left == -1\n",
    "    # Collect only leaf node indices\n",
    "    leaf_indices.append(np.where(is_leaf)[0])\n",
    "leaf_indices = np.array(leaf_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 이미지에 대한 bag of words를 구하는 거!\n",
    "def create_rf_histogram(descriptors, rf_code, leaf_indices, max_leaf_nodes, ensemble='concat'):\n",
    "    # Step 1: Apply descriptors to the forest to get leaf indices\n",
    "    # 여기에서는 index가 전체 node에 대한 index\n",
    "    des_indices = rf_code.apply(descriptors)  # Shape: (n_descriptors, n_trees)\n",
    "\n",
    "    # Step 2: Convert node index to leaf index\n",
    "    converted_indices = np.zeros_like(des_indices)\n",
    "    for tree_idx in range(des_indices.shape[1]):  # Loop over each tree\n",
    "        leaf_map = {leaf: idx for idx, leaf in enumerate(leaf_indices[tree_idx])}\n",
    "        converted_indices[:, tree_idx] = [leaf_map[val] for val in des_indices[:, tree_idx]]\n",
    "\n",
    "    # Step 3: one-hot encoding and concatenate\n",
    "    one_hot_encoded = []\n",
    "    for row in converted_indices:\n",
    "        row_one_hot = []\n",
    "        # tree 마다 one-hot encoding을 하나씩 만들어서 concatenate\n",
    "        for leaf_idx in row:\n",
    "            # Generate a one-hot vector of size max_leaf_nodes\n",
    "            one_hot_vector = np.zeros(max_leaf_nodes)\n",
    "            one_hot_vector[leaf_idx] = 1\n",
    "            row_one_hot.append(one_hot_vector)\n",
    "        # Concatenate the one-hot vectors for each tree\n",
    "        if ensemble == 'sum':\n",
    "            one_hot_encoded.append(np.sum(row_one_hot, axis=0))\n",
    "        else:\n",
    "            one_hot_encoded.append(np.concatenate(row_one_hot))\n",
    "    one_hot_encoded = np.array(one_hot_encoded)\n",
    "    \n",
    "    # Step 4: Normalized histogram -> image 마다 descriptors 개수가 달라서 normalize 해야 함\n",
    "    histogram = one_hot_encoded.sum(axis=0) / one_hot_encoded.sum()\n",
    "    # histogram = one_hot_encoded.sum(axis=0)\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train descriptor extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Extract train descriptors and labels\n",
    "train_descriptors, train_labels = collect_descriptors_with_labels(train_path)\n",
    "print(\"Train descriptor extraction completed.\")\n",
    "ensemble = 'concat'\n",
    "\n",
    "train_bow_rf = []\n",
    "for descriptors in train_descriptors:\n",
    "    image_bow = create_rf_histogram(descriptors, rf_code, leaf_indices, max_leaf_nodes, ensemble=ensemble)\n",
    "    train_bow_rf.append(image_bow)\n",
    "\n",
    "train_bow_rf = np.array(train_bow_rf)\n",
    "\n",
    "x_train = train_bow_rf\n",
    "y_train = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 80)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Extract test descriptors and labels\n",
    "test_descriptors, test_labels = collect_descriptors_with_labels(test_path)\n",
    "print(\"Descriptor extraction completed.\")\n",
    "\n",
    "test_bow_rf = []\n",
    "for descriptors in test_descriptors:\n",
    "    image_bow = create_rf_histogram(descriptors, rf_code, leaf_indices, max_leaf_nodes, ensemble=ensemble)\n",
    "    test_bow_rf.append(image_bow)\n",
    "\n",
    "test_bow_rf = np.array(test_bow_rf)\n",
    "\n",
    "x_test = test_bow_rf\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis-aligned test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_classification(x_train, y_train, x_test, n_estimators=30, max_depth=10, bootstrap=True, random_state=None, max_samples=0.7, max_features=\"sqrt\", criterion='entropy'):\n",
    "    rf_clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, bootstrap=bootstrap, random_state=random_state, max_samples=max_samples, max_features=max_features, criterion=criterion)\n",
    "    # Train ----------------------------------------------------------\n",
    "    tracemalloc.start() \n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    rf_clf.fit(x_train, y_train.ravel())\n",
    "    \n",
    "    train_time = time.perf_counter() - start_time\n",
    "    current, train_peak_memory = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    y_train_pred = rf_clf.predict(x_train)\n",
    "\n",
    "    # Test ----------------------------------------------------------\n",
    "    tracemalloc.start() \n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    y_test_pred = rf_clf.predict(x_test)\n",
    "\n",
    "    test_time = time.perf_counter()- start_time\n",
    "    current, test_peak_memory = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    # Retrieve the maximum depth of each tree in the forest\n",
    "    tree_depths = [estimator.tree_.max_depth for estimator in rf_clf.estimators_]\n",
    "    max_tree_depth = max(tree_depths)\n",
    "\n",
    "    return y_train_pred, y_test_pred, train_time, test_time, train_peak_memory, test_peak_memory, max_tree_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.17165810003643855\n",
      "train accuracy: 0.9866666666666667\n",
      "\n",
      "\n",
      "test time: 0.0018428000039421022\n",
      "test_accuracy: 0.42\n",
      "\n",
      "\n",
      "test_precision: 0.45734997369032904\n",
      "test_recall: 0.42000000000000004\n",
      "\n",
      "\n",
      "max tree depth: 5\n"
     ]
    }
   ],
   "source": [
    "y_train_pred, y_test_pred, train_time, test_time, train_peak_memory, test_peak_memory, max_tree_depth = RF_classification(x_train, y_train, x_test, n_estimators=30, max_depth=5, bootstrap=True, random_state=None, max_samples=0.7, max_features=\"sqrt\", criterion='entropy')\n",
    "\n",
    "train_accuracy = accuracy_score(y_train.T, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test.T, y_test_pred)\n",
    "test_precision = precision_score(y_test.T, y_test_pred, average= \"macro\", zero_division=0)\n",
    "test_recall = recall_score(y_test.T, y_test_pred, average= \"macro\", zero_division=0)\n",
    "\n",
    "print(f'train time: {train_time}')\n",
    "print(f'train accuracy: {train_accuracy}')\n",
    "print('\\n')\n",
    "\n",
    "print(f'test time: {test_time}')\n",
    "print(f'test_accuracy: {test_accuracy}')\n",
    "print('\\n')\n",
    "\n",
    "print(f'test_precision: {test_precision}')\n",
    "print(f'test_recall: {test_recall}')\n",
    "print('\\n')\n",
    "\n",
    "print(f'max tree depth: {max_tree_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-pixel test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_two_pixel_features(x_train, x_test, n_pairs=None, random_seed=None):\n",
    "    x_combined = np.concatenate([x_train, x_test], axis=1)\n",
    "\n",
    "    n_features, n_samples = x_combined.shape\n",
    "\n",
    "    # Set random seed if provided\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "\n",
    "    # Generate all unique pairs of features where i != j\n",
    "    feature_pairs = [(i, j) for i in range(n_features) for j in range(i + 1, n_features)]\n",
    "\n",
    "    # If n_pairs is specified, randomly select a subset of feature pairs\n",
    "    if n_pairs is not None and n_pairs < len(feature_pairs):\n",
    "        feature_pairs = random.sample(feature_pairs, n_pairs)\n",
    "    \n",
    "    # Initialize a new features matrix for pairwise differences\n",
    "    new_features = np.zeros((len(feature_pairs), n_samples))\n",
    "\n",
    "    # Fill in the new features with pairwise differences\n",
    "    for idx, (i, j) in enumerate(feature_pairs):\n",
    "        new_features[idx, :] = x_combined[i, :] - x_combined[j, :]\n",
    "\n",
    "    x_train_2pix = new_features[:, :x_train.shape[1]]\n",
    "    x_test_2pix = new_features[:, x_train.shape[1]:]\n",
    "\n",
    "    return x_train_2pix.T, x_test_2pix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.1733814000035636\n",
      "train accuracy: 0.9933333333333333\n",
      "\n",
      "\n",
      "test time: 0.0018493999959900975\n",
      "test_accuracy: 0.3333333333333333\n",
      "\n",
      "\n",
      "test_precision: 0.38338143549814035\n",
      "test_recall: 0.33333333333333337\n",
      "\n",
      "\n",
      "max tree depth: 10\n"
     ]
    }
   ],
   "source": [
    "n_pairs = x_train.shape[1]\n",
    "# n_pairs = 100\n",
    "x_train_2pix, x_test_2pix = create_two_pixel_features(x_train.T, x_test.T, n_pairs=n_pairs, random_seed=0)\n",
    "y_train_pred, y_test_pred, train_time, test_time, train_peak_memory, test_peak_memory, max_tree_depth = RF_classification(x_train_2pix, y_train, x_test_2pix, n_estimators=30, max_depth=10, bootstrap=True, random_state=None, max_samples=0.7, max_features=\"sqrt\", criterion='entropy')\n",
    "\n",
    "train_accuracy = accuracy_score(y_train.T, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test.T, y_test_pred)\n",
    "test_precision = precision_score(y_test.T, y_test_pred, average= \"macro\", zero_division=0)\n",
    "test_recall = recall_score(y_test.T, y_test_pred, average= \"macro\", zero_division=0)\n",
    "\n",
    "print(f'train time: {train_time}')\n",
    "print(f'train accuracy: {train_accuracy}')\n",
    "print('\\n')\n",
    "\n",
    "print(f'test time: {test_time}')\n",
    "print(f'test_accuracy: {test_accuracy}')\n",
    "print('\\n')\n",
    "\n",
    "print(f'test_precision: {test_precision}')\n",
    "print(f'test_recall: {test_recall}')\n",
    "print('\\n')\n",
    "\n",
    "print(f'max tree depth: {max_tree_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
